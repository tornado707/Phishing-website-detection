{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4698ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing numpy and pandas which are required for data pre-processing\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8311a733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loading the legitimate URLs data to dataframe\n",
    "raw_data0 = pd.read_csv(\"raw_datasets2/legitimate_websites.txt\", sep='delimiter', header=None)\n",
    "raw_data0.columns = ['URLs']\n",
    "raw_data0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b556c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#loading the legitimate URLs data to dataframe\n",
    "raw_data1 = pd.read_csv(\"raw_datasets2/phishing_websites.txt\", sep='delimiter', header=None)\n",
    "raw_data1.columns = ['url']\n",
    "raw_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a680107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction\n",
    "# 1.Checks for IP address in URL (Have_IP)\n",
    "def havingIP(url):\n",
    "    try:\n",
    "        ipaddress.ip_address(url)\n",
    "        ip = 1\n",
    "    except:\n",
    "        ip = 0\n",
    "    return ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89311789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Finding the length of URL and categorizing (URL_Length)\n",
    "def getLength(url):\n",
    "    if len(url) < 54:\n",
    "        length = 0            \n",
    "    else:\n",
    "        length = 1            \n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396bcb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.Checks the presence of @ in URL (Have_At)\n",
    "def haveAtSign(url):\n",
    "    if \"@\" in url:\n",
    "        at = 1    \n",
    "    else:\n",
    "        at = 0    \n",
    "    return at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec213a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Checking for redirection '//' in the url (Redirection)\n",
    "def redirection(url):\n",
    "    pos = url.rfind('//')\n",
    "    if pos > 6:\n",
    "        if pos > 7:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7291b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.Checking for Prefix or Suffix Separated by (-) in the Domain (Prefix/Suffix)\n",
    "from urllib.parse import parse_qsl, urljoin, urlparse\n",
    "def prefixSuffix(url):\n",
    "    if '-' in urlparse(url).netloc:\n",
    "        return 1            # phishing\n",
    "    else:\n",
    "        return 0            # legitimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cc4da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.If the url has more than 3 dots then it is a phishing\n",
    "def sub_domains(url):\n",
    "    if url.count(\".\") < 3:\n",
    "         return 0            # legitimate\n",
    "    else:\n",
    "         return 1            # phishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0707228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#listing shortening services\n",
    "shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
    "                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
    "                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
    "                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
    "                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
    "                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
    "                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
    "                      r\"tr\\.im|link\\.zip\\.net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7508b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Checking for Shortening Services in URL (Tiny_URL)\n",
    "def tinyURL(url):\n",
    "    match=re.search(shortening_services,url)\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0281cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required packages for this section\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import whois\n",
    "import urllib\n",
    "import urllib.request\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d61778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.Web traffic (Web_Traffic)\n",
    "def web_traffic(url):\n",
    "    try:\n",
    "    #Filling the whitespaces in the URL if any\n",
    "        url = urllib.parse.quote(url)\n",
    "        rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\n",
    "        \"REACH\")['RANK']\n",
    "        rank = int(rank)\n",
    "    except TypeError:\n",
    "        return 1\n",
    "    if rank <100000:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb40865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.\n",
    "def domain_registration_length(url):\n",
    "        dns = 0\n",
    "        try:\n",
    "            domain_name = whois.whois(urlparse(url).netloc)\n",
    "        except:\n",
    "            dns = 1\n",
    "        \n",
    "        if dns == 1:\n",
    "            return 1      #phishing\n",
    "        else:\n",
    "            expiration_date = domain_name.expiration_date\n",
    "            today = time.strftime('%Y-%m-%d')\n",
    "            today = datetime.strptime(today, '%Y-%m-%d')\n",
    "            if expiration_date is None:\n",
    "                return 1\n",
    "            elif type(expiration_date) is list or type(today) is list :\n",
    "                return 2     #If it is a type of list then we can't select a single value from list. So,it is regarded as suspected website  \n",
    "            else:\n",
    "                creation_date = domain_name.creation_date\n",
    "                expiration_date = domain_name.expiration_date\n",
    "                if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
    "                    try:\n",
    "                        creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "                        expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "                    except:\n",
    "                        return 2\n",
    "                registration_length = abs((expiration_date - today).days)\n",
    "                if registration_length / 365 <= 1:\n",
    "                    return 1 #phishing\n",
    "                else:\n",
    "                    return 0 # legitimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11.\n",
    "def age_domain(url):\n",
    "        dns = 0\n",
    "        try:\n",
    "            domain_name = whois.whois(urlparse(url).netloc)\n",
    "        except:\n",
    "            dns = 1\n",
    "        \n",
    "        if dns == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            creation_date = domain_name.creation_date\n",
    "            expiration_date = domain_name.expiration_date\n",
    "            if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
    "                try:\n",
    "                    creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "                    expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "                except:\n",
    "                    return 2\n",
    "            if ((expiration_date is None) or (creation_date is None)):\n",
    "                return 1\n",
    "            elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n",
    "                return 2\n",
    "            else:\n",
    "                ageofdomain = abs((expiration_date - creation_date).days)\n",
    "                if ((ageofdomain/30) < 6):\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba38de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12.\n",
    "def dns_record(url):\n",
    "    dns = 0\n",
    "    try:\n",
    "        domain_name = whois.whois(domain)\n",
    "        print(domain_name)\n",
    "    except:\n",
    "        dns = 1\n",
    "        \n",
    "    if dns == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return dns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc495e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.\n",
    "import socket\n",
    "def statistical_report(url):\n",
    "    hostname = url\n",
    "    h = [(x.start(0), x.end(0)) for x in re.finditer('https://|http://|www.|https://www.|http://www.', hostname)]\n",
    "    z = int(len(h))\n",
    "    if z != 0:\n",
    "        y = h[0][1]\n",
    "        hostname = hostname[y:]\n",
    "        h = [(x.start(0), x.end(0)) for x in re.finditer('/', hostname)]\n",
    "        z = int(len(h))\n",
    "        if z != 0:\n",
    "            hostname = hostname[:h[0][0]]\n",
    "    url_match=re.search('at\\.ua|usa\\.cc|baltazarpresentes\\.com\\.br|pe\\.hu|esy\\.es|hol\\.es|sweddy\\.com|myjino\\.ru|96\\.lt|ow\\.ly',url)\n",
    "    try:\n",
    "        ip_address = socket.gethostbyname(hostname)\n",
    "        ip_match=re.search('146\\.112\\.61\\.108|213\\.174\\.157\\.151|121\\.50\\.168\\.88|192\\.185\\.217\\.116|78\\.46\\.211\\.158|181\\.174\\.165\\.13|46\\.242\\.145\\.103|121\\.50\\.168\\.40|83\\.125\\.22\\.219|46\\.242\\.145\\.98|107\\.151\\.148\\.44|107\\.151\\.148\\.107|64\\.70\\.19\\.203|199\\.184\\.144\\.27|107\\.151\\.148\\.108|107\\.151\\.148\\.109|119\\.28\\.52\\.61|54\\.83\\.43\\.69|52\\.69\\.166\\.231|216\\.58\\.192\\.225|118\\.184\\.25\\.86|67\\.208\\.74\\.71|23\\.253\\.126\\.58|104\\.239\\.157\\.210|175\\.126\\.123\\.219|141\\.8\\.224\\.221|10\\.10\\.10\\.10|43\\.229\\.108\\.32|103\\.232\\.215\\.140|69\\.172\\.201\\.153|216\\.218\\.185\\.162|54\\.225\\.104\\.146|103\\.243\\.24\\.98|199\\.59\\.243\\.120|31\\.170\\.160\\.61|213\\.19\\.128\\.77|62\\.113\\.226\\.131|208\\.100\\.26\\.234|195\\.16\\.127\\.102|195\\.16\\.127\\.157|34\\.196\\.13\\.28|103\\.224\\.212\\.222|172\\.217\\.4\\.225|54\\.72\\.9\\.51|192\\.64\\.147\\.141|198\\.200\\.56\\.183|23\\.253\\.164\\.103|52\\.48\\.191\\.26|52\\.214\\.197\\.72|87\\.98\\.255\\.18|209\\.99\\.17\\.27|216\\.38\\.62\\.18|104\\.130\\.124\\.96|47\\.89\\.58\\.141|78\\.46\\.211\\.158|54\\.86\\.225\\.156|54\\.82\\.156\\.19|37\\.157\\.192\\.102|204\\.11\\.56\\.48|110\\.34\\.231\\.42',ip_address)  \n",
    "    except:\n",
    "        return 1\n",
    "\n",
    "    if url_match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa31dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract features\n",
    "def featureExtraction(url,label):\n",
    "    features = []\n",
    "    #Address bar based features (10)\n",
    "    features.append(havingIP(url))\n",
    "    features.append(getLength(url))\n",
    "    features.append(haveAtSign(url))\n",
    "    features.append(redirection(url))\n",
    "    features.append(prefixSuffix(url))\n",
    "    features.append(sub_domains(url))\n",
    "    features.append(tinyURL(url))\n",
    "    features.append(statistical_report(url))\n",
    "  #Domain based features (4)\n",
    "    dns = 0\n",
    "    try:\n",
    "        domain_name = whois.whois(urlparse(url).netloc)\n",
    "    except:\n",
    "        dns = 1\n",
    "    features.append(dns_record(url))\n",
    "    features.append(web_traffic(url))\n",
    "    features.append(1 if dns == 1 else age_domain(domain_name))\n",
    "    features.append(1 if dns == 1 else domain_registration_length(domain_name))\n",
    "  \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a77a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9465ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the feautres & storing them in a list\n",
    "legi_features = []\n",
    "label = 0\n",
    "\n",
    "for i in range(0, 5730):\n",
    "    url = raw_data0['URLs'][i]\n",
    "    legi_features.append(featureExtraction(url,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dc3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the list to dataframe\n",
    "feature_names = ['Domain', 'Have_IP', 'URL_Length', 'Have_At', 'Redirection', 'Prefix/Suffix', 'SubDomains'\n",
    "                    'TinyURL',  'StatisticalReport', 'DnsRecord', \n",
    "                      'WebTraffic', 'DomainAge', 'DomainRegistrationLength']\n",
    "\n",
    "legitimate = pd.DataFrame(legi_features, columns= feature_names)\n",
    "legitimate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811de96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "legitimate.to_csv('legitimate.csv', index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
